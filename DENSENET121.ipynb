{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZbU4O6S5mWWK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import os, random\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.class_weights = self.compute_class_weights()\n",
        "\n",
        "    def compute_class_weights(self):\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(self.labels), y=self.labels)\n",
        "        return torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label)"
      ],
      "metadata": {
        "id": "xJ8RaRbumcJ6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/MultiClass_m-20240806T134043Z-001/MultiClass_m\"\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
        "\n",
        "img_paths, labels = [], []\n",
        "for label in classes:\n",
        "    folder = os.path.join(data_dir, label)\n",
        "    for img_name in os.listdir(folder):\n",
        "        img_paths.append(os.path.join(folder, img_name))\n",
        "        labels.append(class_to_idx[label])\n",
        "def oversample_dataset(img_paths, labels):\n",
        "    class_counts = Counter(labels)\n",
        "    max_count = max(class_counts.values())\n",
        "    new_img_paths, new_labels = img_paths.copy(), labels.copy()\n",
        "\n",
        "    for cls, count in class_counts.items():\n",
        "        if count < max_count:\n",
        "            diff = max_count - count\n",
        "            cls_indices = [i for i, y in enumerate(labels) if y == cls]\n",
        "            for _ in range(diff):\n",
        "                idx = random.choice(cls_indices)\n",
        "                new_img_paths.append(img_paths[idx])\n",
        "                new_labels.append(labels[idx])\n",
        "    return new_img_paths, new_labels\n",
        "\n",
        "oversampled_img_paths, oversampled_labels = oversample_dataset(img_paths, labels)\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    oversampled_img_paths, oversampled_labels, test_size=0.2, stratify=oversampled_labels\n",
        ")\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    test_paths, test_labels, test_size=0.5, stratify=test_labels\n",
        ")\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "train_dataset = CustomDataset(train_paths, train_labels, transform)\n",
        "val_dataset = CustomDataset(val_paths, val_labels, transform)\n",
        "test_dataset = CustomDataset(test_paths, test_labels, transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "class WeightedDenseNet121(nn.Module):\n",
        "    def __init__(self, num_classes, class_weights):\n",
        "        super().__init__()\n",
        "        self.model = models.densenet121(pretrained=True)\n",
        "        in_features = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Linear(in_features, num_classes)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def forward(self, x, labels=None):\n",
        "        logits = self.model(x)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            criterion = nn.CrossEntropyLoss(weight=self.class_weights.to(x.device))\n",
        "            loss = criterion(logits, labels)\n",
        "        return (loss, logits) if loss is not None else logits\n",
        "\n",
        "num_classes = len(class_to_idx)\n",
        "model = WeightedDenseNet121(num_classes, train_dataset.class_weights)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss, outputs = model(imgs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(\"\\nTest Results:\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall   : {recall:.4f}\")\n",
        "print(f\"F1 Score : {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsW1kfW6miqW",
        "outputId": "9b735f73-c122-407a-96cc-500930c86ea0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Accuracy : 0.69\n",
            "Precision: 0.68\n",
            "Recall   : 0.68\n",
            "F1 Score : 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLYRP_CKmwtn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}