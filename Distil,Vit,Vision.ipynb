{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DISTIL+DENSE121**"
      ],
      "metadata": {
        "id": "O8lZkIsLkJxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchvision pandas scikit-learn imbalanced-learn tqdm\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "image_dir = \"/content/drive/MyDrive/Colab Notebooks/MultiClass_m-20240806T134043Z-001/MultiClass_m\"\n",
        "text_path = \"/content/drive/MyDrive/Colab Notebooks/updated_meme_classification_data.xlsx\"\n",
        "\n",
        "df = pd.read_excel(text_path)\n",
        "df['label'] = LabelEncoder().fit_transform(df['label'])\n",
        "df['image_path'] = df['image_name'].apply(lambda x: os.path.join(image_dir, x))\n",
        "\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, transform=None, max_len=128):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "        self.max_len = max_len\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text, img_path, label = str(row['text']), row['image_path'], row['label']\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        tokens = self.tokenizer(text, truncation=True, padding='max_length',\n",
        "                                max_length=self.max_len, return_tensors='pt')\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def extract_image_features(model_name, images):\n",
        "    with torch.no_grad():\n",
        "        if model_name == \"densenet\":\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1').features.to(device)\n",
        "            model.eval()\n",
        "            feats = model(images).mean([2, 3])\n",
        "    return feats.cpu().numpy()\n",
        "\n",
        "def extract_text_features(model_name, input_ids, attention_mask):\n",
        "    with torch.no_grad():\n",
        "        model = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)\n",
        "        model.eval()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        feats = outputs.last_hidden_state[:, 0, :]\n",
        "    return feats.cpu().numpy()\n",
        "\n",
        "def early_fusion(img_features, txt_features):\n",
        "    return np.concatenate([img_features, txt_features], axis=1)\n",
        "\n",
        "def train_eval_model(X_train, y_train, X_test, y_test, label=\"Early Fusion\"):\n",
        "    clf = RandomForestClassifier(n_estimators=250, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    return clf, preds, (acc, prec, rec, f1)\n",
        "\n",
        "def late_fusion(early_preds, early_probs, y_train, y_test):\n",
        "    meta_train = np.hstack([early_probs, early_preds.reshape(-1, 1)])\n",
        "    meta_test = np.hstack([early_probs[:len(y_test)], early_preds[:len(y_test)].reshape(-1, 1)])\n",
        "    meta_clf = LogisticRegression(max_iter=500)\n",
        "    meta_clf.fit(meta_train, y_train[:len(meta_train)])\n",
        "    preds = meta_clf.predict(meta_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    print(f\"Fusion -> Acc: {acc:.4f}, Prec: {prec:.4f}, Rec: {rec:.4f}, F1: {f1:.4f}\")\n",
        "    return (acc, prec, rec, f1)\n",
        "\n",
        "def run_fusion_experiment(text_model, img_model):\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "    train_ds = MemeDataset(train_df, tokenizer, image_transform)\n",
        "    test_ds = MemeDataset(test_df, tokenizer, image_transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=16)\n",
        "    test_loader = DataLoader(test_ds, batch_size=16)\n",
        "\n",
        "    def get_features(loader):\n",
        "        img_feats, txt_feats, labels = [], [], []\n",
        "        for batch in tqdm(loader):\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbl = batch[\"label\"].numpy()\n",
        "            img_feats.append(extract_image_features(img_model, imgs))\n",
        "            txt_feats.append(extract_text_features(text_model, ids, mask))\n",
        "            labels.extend(lbl)\n",
        "        return np.vstack(img_feats), np.vstack(txt_feats), np.array(labels)\n",
        "\n",
        "    X_train_img, X_train_txt, y_train = get_features(train_loader)\n",
        "    X_test_img, X_test_txt, y_test = get_features(test_loader)\n",
        "\n",
        "    X_train = early_fusion(X_train_img, X_train_txt)\n",
        "    X_test = early_fusion(X_test_img, X_test_txt)\n",
        "\n",
        "    sm = SMOTE(random_state=42)\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "    clf, preds, _ = train_eval_model(X_train, y_train, X_test, y_test, label=\"Early Fusion\")\n",
        "    probs = clf.predict_proba(X_test)\n",
        "    late_fusion(preds, probs, y_train, y_test)\n",
        "\n",
        "run_fusion_experiment(\"distilbert\", \"densenet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KRICXDxkU1h",
        "outputId": "05c8e309-5f68-46a9-90ab-e0339ed97c19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusion:\n",
            "Accuracy : 0.801\n",
            "Precision: 0.803\n",
            "Recall   : 0.809\n",
            "F1-Score : 0.798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5uj5tuk3kHTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DistilBERT + ViT**"
      ],
      "metadata": {
        "id": "HEm5Of2vqlLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torchvision pandas scikit-learn imbalanced-learn tqdm\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from transformers import DistilBertTokenizer, DistilBertModel, ViTModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "image_dir = \"/content/drive/MyDrive/Colab Notebooks/MultiClass_m-20240806T134043Z-001/MultiClass_m\"\n",
        "text_path = \"/content/drive/MyDrive/Colab Notebooks/updated_meme_classification_data.xlsx\"\n",
        "\n",
        "df = pd.read_excel(text_path)\n",
        "df['label'] = LabelEncoder().fit_transform(df['label'])\n",
        "df['image_path'] = df['image_name'].apply(lambda x: os.path.join(image_dir, x))\n",
        "\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, transform=None, max_len=128):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "        self.max_len = max_len\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text, img_path, label = str(row['text']), row['image_path'], row['label']\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        tokens = self.tokenizer(text, truncation=True, padding='max_length',\n",
        "                                max_length=self.max_len, return_tensors='pt')\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"input_ids\": tokens[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": tokens[\"attention_mask\"].squeeze(0),\n",
        "            \"label\": torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def extract_image_features(model_name, images):\n",
        "    with torch.no_grad():\n",
        "        if model_name == \"vit\":\n",
        "            vit = ViTModel.from_pretrained('google/vit-base-patch16-224').to(device)\n",
        "            vit.eval()\n",
        "            outputs = vit(images)\n",
        "            feats = outputs.pooler_output\n",
        "        elif model_name == \"densenet\":\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1').features.to(device)\n",
        "            model.eval()\n",
        "            feats = model(images).mean([2,3])\n",
        "    return feats.cpu().numpy()\n",
        "\n",
        "def extract_text_features(model_name, input_ids, attention_mask):\n",
        "    with torch.no_grad():\n",
        "        if model_name == \"distilbert\":\n",
        "            model = DistilBertModel.from_pretrained('distilbert-base-uncased').to(device)\n",
        "        model.eval()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        feats = outputs.last_hidden_state[:, 0, :]\n",
        "    return feats.cpu().numpy()\n",
        "\n",
        "def early_fusion(img_features, txt_features):\n",
        "    return np.concatenate([img_features, txt_features], axis=1)\n",
        "\n",
        "def train_eval_model(X_train, y_train, X_test, y_test, label=\"Early Fusion\"):\n",
        "    clf = RandomForestClassifier(n_estimators=250, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    return clf, preds, (acc, prec, rec, f1)\n",
        "\n",
        "def late_fusion(early_preds, early_probs, y_train, y_test):\n",
        "    meta_train = np.hstack([early_probs, early_preds.reshape(-1,1)])\n",
        "    meta_test = np.hstack([early_probs[:len(y_test)], early_preds[:len(y_test)].reshape(-1,1)])\n",
        "    meta_clf = LogisticRegression(max_iter=500)\n",
        "    meta_clf.fit(meta_train, y_train[:len(meta_train)])\n",
        "    preds = meta_clf.predict(meta_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    rec = recall_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, preds, average='weighted', zero_division=0)\n",
        "    print(f\"Fusion Acc: {acc:.3f}, Prec: {prec:.3f}, Rec: {rec:.3f}, F1: {f1:.3f}\")\n",
        "    return (acc, prec, rec, f1)\n",
        "\n",
        "def run_fusion_experiment(text_model, img_model):\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "    train_ds = MemeDataset(train_df, tokenizer, image_transform)\n",
        "    test_ds = MemeDataset(test_df, tokenizer, image_transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=16)\n",
        "    test_loader = DataLoader(test_ds, batch_size=16)\n",
        "\n",
        "    def get_features(loader):\n",
        "        img_feats, txt_feats, labels = [], [], []\n",
        "        for batch in tqdm(loader):\n",
        "            imgs = batch[\"image\"].to(device)\n",
        "            ids = batch[\"input_ids\"].to(device)\n",
        "            mask = batch[\"attention_mask\"].to(device)\n",
        "            lbl = batch[\"label\"].numpy()\n",
        "            img_feats.append(extract_image_features(img_model, imgs))\n",
        "            txt_feats.append(extract_text_features(text_model, ids, mask))\n",
        "            labels.extend(lbl)\n",
        "        return np.vstack(img_feats), np.vstack(txt_feats), np.array(labels)\n",
        "\n",
        "    X_train_img, X_train_txt, y_train = get_features(train_loader)\n",
        "    X_test_img, X_test_txt, y_test = get_features(test_loader)\n",
        "\n",
        "    X_train = early_fusion(X_train_img, X_train_txt)\n",
        "    X_test = early_fusion(X_test_img, X_test_txt)\n",
        "\n",
        "    sm = SMOTE(random_state=42)\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "    clf, preds, _ = train_eval_model(X_train, y_train, X_test, y_test, label=\"Early Fusion\")\n",
        "    probs = clf.predict_proba(X_test)\n",
        "    late_fusion(preds, probs, y_train, y_test)\n",
        "\n",
        "run_fusion_experiment(\"distilbert\", \"vit\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs91sHSjrQ-y",
        "outputId": "f5abd90a-a619-4773-8672-3767b1e497e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusion\n",
            "Accuracy : 0.750\n",
            "Precision: 0.772\n",
            "Recall   : 0.755\n",
            "F1-Score : 0.772\n"
          ]
        }
      ]
    }
  ]
}