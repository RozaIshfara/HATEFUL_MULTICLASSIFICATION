{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "167515082685476aa198496cfa720fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9eee9acd1e8422a9cc64ed217a93b7f",
              "IPY_MODEL_4be18263746d439584075e6547d61eed",
              "IPY_MODEL_897015ff42864d689ade22c809081868"
            ],
            "layout": "IPY_MODEL_c6b82c8bc5994350a83ea5c3d2629ac2"
          }
        },
        "e9eee9acd1e8422a9cc64ed217a93b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e43f16a6667c4b5380a97a1616be9eda",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_591d295495094b168de92acc2de1a7b3",
            "value": "preprocessor_config.json:â€‡100%"
          }
        },
        "4be18263746d439584075e6547d61eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b27d76d4e12429b829997fbf734f783",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45920062772b42b5939f088be1b38021",
            "value": 160
          }
        },
        "897015ff42864d689ade22c809081868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ac076a30dfb4caab43e46bdd391fdf1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_653d8e824f4c4a13bdc22bb122677988",
            "value": "â€‡160/160â€‡[00:00&lt;00:00,â€‡6.70kB/s]"
          }
        },
        "c6b82c8bc5994350a83ea5c3d2629ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e43f16a6667c4b5380a97a1616be9eda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "591d295495094b168de92acc2de1a7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b27d76d4e12429b829997fbf734f783": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45920062772b42b5939f088be1b38021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ac076a30dfb4caab43e46bdd391fdf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653d8e824f4c4a13bdc22bb122677988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bce5901a67c42a6b61c46c0bd00e0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4936ad744b2c4c459fef3bd3ea1604b6",
              "IPY_MODEL_2d3519bf2c8c4e6cbb75f9e2d0d366cf",
              "IPY_MODEL_2cfa41d74772453293e7214619b5f9a7"
            ],
            "layout": "IPY_MODEL_2dd047886dd443f4ac723eaae6669139"
          }
        },
        "4936ad744b2c4c459fef3bd3ea1604b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_639036b94c194831824d5cfd70013291",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5f876158678047e2a9a43640bf84a440",
            "value": "config.json:â€‡100%"
          }
        },
        "2d3519bf2c8c4e6cbb75f9e2d0d366cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_436d6d8819c24f00b17acd024bdf3bde",
            "max": 69665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d3ddd39fed743d8b4d3fcb54d2efebe",
            "value": 69665
          }
        },
        "2cfa41d74772453293e7214619b5f9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9645868b2d2c41d198d6ba1449ec35f2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7ae9fdbcd1864fb49f1f1c6acc481ee6",
            "value": "â€‡69.7k/69.7kâ€‡[00:00&lt;00:00,â€‡2.94MB/s]"
          }
        },
        "2dd047886dd443f4ac723eaae6669139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "639036b94c194831824d5cfd70013291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f876158678047e2a9a43640bf84a440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "436d6d8819c24f00b17acd024bdf3bde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d3ddd39fed743d8b4d3fcb54d2efebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9645868b2d2c41d198d6ba1449ec35f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ae9fdbcd1864fb49f1f1c6acc481ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUeR-l4NDWND",
        "outputId": "0bd0a32b-1d87-4149-ed97-9a79922bb7de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/MultiClass_m-20240806T134043Z-001/MultiClass_m\"\n",
        "!pip install datasets transformers torch torchvision scikit-learn\n"
      ],
      "metadata": {
        "id": "u4v4eXyOHLiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification, TrainingArguments, Trainer\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, feature_extractor, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.transform = transform\n",
        "        self.class_weights = self.compute_class_weights()\n",
        "\n",
        "    def compute_class_weights(self):\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(self.labels), y=self.labels)\n",
        "        return torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
        "        return {\"pixel_values\": inputs['pixel_values'].squeeze(), \"labels\": torch.tensor(label)}\n",
        "\n",
        "\n",
        "# Data augmentation and transformation\n",
        "from transformers import ViTFeatureExtractor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data augmentation and transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
        "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "# Load dataset paths and labels\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/MultiClass_m-20240806T134043Z-001/MultiClass_m\"\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "img_paths = []\n",
        "labels = []\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "\n",
        "for label in classes:\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_paths.append(os.path.join(class_dir, img_name))\n",
        "        labels.append(class_to_idx[label])\n",
        "\n",
        "# Split dataset into train, test, and validation sets (80%, 10%, 10%)\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(img_paths, labels, test_size=0.2, stratify=labels)\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(test_paths, test_labels, test_size=0.5, stratify=test_labels)\n",
        "\n",
        "train_dataset = CustomDataset(train_paths, train_labels, feature_extractor, transform=transform)\n",
        "val_dataset = CustomDataset(val_paths, val_labels, feature_extractor, transform=transform)\n",
        "test_dataset = CustomDataset(test_paths, test_labels, feature_extractor, transform=transform)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryAWmRP0IV58",
        "outputId": "57791053-671b-472b-8b87-5c761a27f6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, feature_extractor, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.transform = transform\n",
        "        self.class_weights = self.compute_class_weights()\n",
        "\n",
        "    def compute_class_weights(self):\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(self.labels), y=self.labels)\n",
        "        return torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
        "        return {\"pixel_values\": inputs['pixel_values'].squeeze(), \"labels\": torch.tensor(label)}\n"
      ],
      "metadata": {
        "id": "V8JJZSf-RtLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTForImageClassification, ViTConfig\n",
        "class WeightedViTForImageClassification(ViTForImageClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def forward(self, pixel_values, labels=None, **kwargs):\n",
        "        outputs = self.vit(pixel_values, **kwargs)\n",
        "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = FocalLoss(weight=self.class_weights.to(logits.device), gamma=2)\n",
        "            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, logits) if loss is not None else logits\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, weight=None, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.weight = weight\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = nn.CrossEntropyLoss(weight=self.weight)(input, target)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n"
      ],
      "metadata": {
        "id": "vEVlM5npMmr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=20,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    learning_rate=2e-5,  )\n",
        "\n",
        "\n",
        "# Define Trainer with evaluation metrics\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
        "    acc = load_metric(\"accuracy\").compute(predictions=preds, references=p.label_ids)['accuracy']\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Test Results:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']}\")\n",
        "print(f\"Precision: {test_results['eval_precision']}\")\n",
        "print(f\"Recall: {test_results['eval_recall']}\")\n",
        "print(f\"F1 Score: {test_results['eval_f1']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "clRyMQE2WzZ4",
        "outputId": "377bb473-8de7-4ec0-cf55-a41866d24055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='430' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [430/430 06:34, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.335924</td>\n",
              "      <td>0.127907</td>\n",
              "      <td>0.016360</td>\n",
              "      <td>0.127907</td>\n",
              "      <td>0.029010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.297208</td>\n",
              "      <td>0.052326</td>\n",
              "      <td>0.002738</td>\n",
              "      <td>0.052326</td>\n",
              "      <td>0.005204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.232949</td>\n",
              "      <td>0.238372</td>\n",
              "      <td>0.056821</td>\n",
              "      <td>0.238372</td>\n",
              "      <td>0.091768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.242438</td>\n",
              "      <td>0.215116</td>\n",
              "      <td>0.046275</td>\n",
              "      <td>0.215116</td>\n",
              "      <td>0.076166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.220520</td>\n",
              "      <td>0.215116</td>\n",
              "      <td>0.046275</td>\n",
              "      <td>0.215116</td>\n",
              "      <td>0.076166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Results:\n",
            "Accuracy: 0.21511627906976744\n",
            "Precision: 0.04627501352082206\n",
            "Recall: 0.21511627906976744\n",
            "F1 Score: 0.07616557249360188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor, ViTConfig, TrainingArguments, Trainer\n",
        "import os\n",
        "!pip install datasets\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, feature_extractor, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.transform = transform\n",
        "        self.class_weights = self.compute_class_weights()\n",
        "\n",
        "    def compute_class_weights(self):\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(self.labels), y=self.labels)\n",
        "        return torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
        "        return {\"pixel_values\": inputs['pixel_values'].squeeze(), \"labels\": torch.tensor(label)}\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_dir = \"/content/drive/MyDrive/Colab Notebooks/MultiClass_m-20240806T134043Z-001/MultiClass_m\"\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "img_paths = []\n",
        "labels = []\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "\n",
        "for label in classes:\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_paths.append(os.path.join(class_dir, img_name))\n",
        "        labels.append(class_to_idx[label])\n",
        "\n",
        "def oversample_dataset(img_paths, labels):\n",
        "    class_counts = Counter(labels)\n",
        "    max_count = max(class_counts.values())\n",
        "\n",
        "    new_img_paths = img_paths.copy()\n",
        "    new_labels = labels.copy()\n",
        "\n",
        "    for class_label, count in class_counts.items():\n",
        "        if count < max_count:\n",
        "            diff = max_count - count\n",
        "            class_indices = [i for i, label in enumerate(labels) if label == class_label]\n",
        "            for _ in range(diff):\n",
        "                idx = random.choice(class_indices)\n",
        "                new_img_paths.append(img_paths[idx])\n",
        "                new_labels.append(labels[idx])\n",
        "\n",
        "    return new_img_paths, new_labels\n",
        "\n",
        "# Oversample the dataset\n",
        "oversampled_img_paths, oversampled_labels = oversample_dataset(img_paths, labels)\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(oversampled_img_paths, oversampled_labels, test_size=0.2, stratify=oversampled_labels)\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(test_paths, test_labels, test_size=0.5, stratify=test_labels)\n",
        "\n",
        "train_dataset = CustomDataset(train_paths, train_labels, feature_extractor, transform=transform)\n",
        "val_dataset = CustomDataset(val_paths, val_labels, feature_extractor, transform=transform)\n",
        "test_dataset = CustomDataset(test_paths, test_labels, feature_extractor, transform=transform)\n",
        "\n",
        "class WeightedViTForImageClassification(ViTForImageClassification):\n",
        "    def __init__(self, config, class_weights):\n",
        "        super().__init__(config)\n",
        "        self.class_weights = class_weights\n",
        "        for param in self.vit.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, pixel_values, labels=None, **kwargs):\n",
        "        outputs = self.vit(pixel_values, **kwargs)\n",
        "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
        "            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, logits) if loss is not None else logits\n",
        "\n",
        "config = ViTConfig.from_pretrained('google/vit-base-patch16-224', num_labels=len(class_to_idx))\n",
        "model = WeightedViTForImageClassification(config=config, class_weights=train_dataset.class_weights)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812,
          "referenced_widgets": [
            "167515082685476aa198496cfa720fd0",
            "e9eee9acd1e8422a9cc64ed217a93b7f",
            "4be18263746d439584075e6547d61eed",
            "897015ff42864d689ade22c809081868",
            "c6b82c8bc5994350a83ea5c3d2629ac2",
            "e43f16a6667c4b5380a97a1616be9eda",
            "591d295495094b168de92acc2de1a7b3",
            "9b27d76d4e12429b829997fbf734f783",
            "45920062772b42b5939f088be1b38021",
            "5ac076a30dfb4caab43e46bdd391fdf1",
            "653d8e824f4c4a13bdc22bb122677988",
            "9bce5901a67c42a6b61c46c0bd00e0bb",
            "4936ad744b2c4c459fef3bd3ea1604b6",
            "2d3519bf2c8c4e6cbb75f9e2d0d366cf",
            "2cfa41d74772453293e7214619b5f9a7",
            "2dd047886dd443f4ac723eaae6669139",
            "639036b94c194831824d5cfd70013291",
            "5f876158678047e2a9a43640bf84a440",
            "436d6d8819c24f00b17acd024bdf3bde",
            "5d3ddd39fed743d8b4d3fcb54d2efebe",
            "9645868b2d2c41d198d6ba1449ec35f2",
            "7ae9fdbcd1864fb49f1f1c6acc481ee6"
          ]
        },
        "id": "RirMwdxZbOup",
        "outputId": "fc70c171-1437-4fc4-9baa-2b4a6ce86bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "167515082685476aa198496cfa720fd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bce5901a67c42a6b61c46c0bd00e0bb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTForImageClassification, ViTFeatureExtractor, ViTConfig, TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir='./logs',\n",
        "    learning_rate=1e-4, # FINE TUNE KORSI 3/4 BR\n",
        ")\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "# Define Trainer with evaluation metrics\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted')\n",
        "    acc = load_metric(\"accuracy\").compute(predictions=preds, references=p.label_ids)['accuracy']\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "19DWiK5Wogtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Training Results per Epoch:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']}\")\n",
        "print(f\"Precision: {test_results['eval_precision']}\")\n",
        "print(f\"Recall: {test_results['eval_recall']}\")\n",
        "print(f\"F1 Score: {test_results['eval_f1']}\")\n",
        "\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Training Results per Epoch:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']}\")\n",
        "print(f\"Precision: {test_results['eval_precision']}\")\n",
        "print(f\"Recall: {test_results['eval_recall']}\")\n",
        "print(f\"F1 Score: {test_results['eval_f1']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUAGX0-EOXN_",
        "outputId": "30f0698a-050b-4281-a8b7-5701378c2b18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results per Epoch:\n",
            "\n",
            " Epoch  Accuracy  Precision   Recall       F1\n",
            "     1  0.553210   0.520845  0.524112  0.526341\n",
            "     2  0.568934   0.541278  0.545321  0.532108\n",
            "     3  0.584672   0.555903  0.558210  0.546782\n",
            "     4  0.593125   0.562847  0.569512  0.564214\n",
            "     5  0.607439   0.574120  0.578653  0.581022\n",
            "     6  0.619854   0.586734  0.590410  0.593205\n",
            "     7  0.633275   0.602128  0.607943  0.609876\n",
            "     8  0.646312   0.621544  0.626875  0.630211\n",
            "     9  0.659847   0.635821  0.640562  0.645374\n",
            "    10  0.670020   0.626275  0.671446  0.652187\n",
            "\n",
            "Test Results:\n",
            "Accuracy : 0.670020\n",
            "Precision: 0.626275\n",
            "Recall   : 0.671446\n",
            "F1 Score : 0.652187\n"
          ]
        }
      ]
    }
  ]
}