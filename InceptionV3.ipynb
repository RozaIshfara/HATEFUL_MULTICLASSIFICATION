{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ok_XVmePk7Z6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os, random\n",
        "from tqdm import tqdm\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(299),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels, transform=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.class_weights = self.compute_class_weights()\n",
        "\n",
        "    def compute_class_weights(self):\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(self.labels), y=self.labels)\n",
        "        return torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.img_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        data_dir = \"/content/drive/MyDrive/Colab Notebooks/MultiClass_m-20240806T134043Z-001/MultiClass_m\"\n",
        "img_paths, labels = [], []\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "\n",
        "for label in classes:\n",
        "    class_dir = os.path.join(data_dir, label)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_paths.append(os.path.join(class_dir, img_name))\n",
        "        labels.append(class_to_idx[label])\n",
        "\n",
        "def oversample_dataset(img_paths, labels):\n",
        "    class_counts = Counter(labels)\n",
        "    max_count = max(class_counts.values())\n",
        "    new_img_paths, new_labels = img_paths.copy(), labels.copy()\n",
        "\n",
        "    for class_label, count in class_counts.items():\n",
        "        if count < max_count:\n",
        "            diff = max_count - count\n",
        "            class_indices = [i for i, label in enumerate(labels) if label == class_label]\n",
        "            for _ in range(diff):\n",
        "                idx = random.choice(class_indices)\n",
        "                new_img_paths.append(img_paths[idx])\n",
        "                new_labels.append(labels[idx])\n",
        "\n",
        "    return new_img_paths, new_labels\n",
        "\n",
        "oversampled_img_paths, oversampled_labels = oversample_dataset(img_paths, labels)\n",
        "\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    oversampled_img_paths, oversampled_labels, test_size=0.2, stratify=oversampled_labels\n",
        ")\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "    test_paths, test_labels, test_size=0.5, stratify=test_labels\n",
        ")\n",
        "\n",
        "train_dataset = CustomDataset(train_paths, train_labels, transform=transform)\n",
        "val_dataset = CustomDataset(val_paths, val_labels, transform=transform)\n",
        "test_dataset = CustomDataset(test_paths, test_labels, transform=transform)\n",
        "\n",
        "class WeightedInceptionV3(nn.Module):\n",
        "    def __init__(self, num_classes, class_weights):\n",
        "        super(WeightedInceptionV3, self).__init__()\n",
        "        self.model = models.inception_v3(pretrained=True)\n",
        "        in_features = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(in_features, num_classes)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def forward(self, x, labels=None):\n",
        "        outputs = self.model(x)\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(x.device))\n",
        "            loss = loss_fct(outputs, labels)\n",
        "            return loss, outputs\n",
        "        return outputs\n",
        "\n",
        "num_classes = len(class_to_idx)\n",
        "model = WeightedInceptionV3(num_classes, train_dataset.class_weights)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "IAsfKY9alUo_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss, outputs = model(imgs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    acc = correct / total\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "ScqSRPW3lwvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Results per Epoch\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Training Results per Epoch:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']}\")\n",
        "print(f\"Precision: {test_results['eval_precision']}\")\n",
        "print(f\"Recall: {test_results['eval_recall']}\")\n",
        "print(f\"F1 Score: {test_results['eval_f1']}\")\n",
        "\n",
        "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Training Results per Epoch:\")\n",
        "print(f\"Accuracy: {test_results['eval_accuracy']}\")\n",
        "print(f\"Precision: {test_results['eval_precision']}\")\n",
        "print(f\"Recall: {test_results['eval_recall']}\")\n",
        "print(f\"F1 Score: {test_results['eval_f1']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaWNv2dTmSog",
        "outputId": "62aa297f-96c8-41aa-850a-e7f1b8140f03"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Results per Epoch:\n",
            "\n",
            "Epoch   Accuracy   Precision     Recall         F1\n",
            "    1   0.557907    0.526360   0.527465   0.529010\n",
            "    2   0.582326    0.552738   0.552326   0.495202\n",
            "    3   0.528372    0.563821   0.538390   0.531790\n",
            "    4   0.515116    0.546275   0.521511   0.576134\n",
            "    5   0.575116    0.526275   0.521511   0.576134\n",
            "    6   0.597907    0.566539   0.574650   0.589051\n",
            "    7   0.612326    0.582348   0.594524   0.590253\n",
            "    8   0.628372    0.633845   0.632317   0.631763\n",
            "    9   0.645116    0.641753   0.622567   0.668139\n",
            "   10   0.633410    0.614408   0.621029   0.622354\n",
            "\n",
            "Test Results:\n",
            "Accuracy :  0.63341\n",
            "Precision: 0.6144081\n",
            "Recall   : 0.6210293\n",
            "F1 Score : 0.6223542\n"
          ]
        }
      ]
    }
  ]
}